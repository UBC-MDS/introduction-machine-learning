---
format: live-html
---

<script src='../../src/quiz.js'></script>

# 4.1. Exercises

## Classifying Examples by Hand

Consider this toy dataset:

![](../../static/module4/Q14.png){fig-align="center" width="40%" fig-alt="404 image"}


**Question 1**

![](../../static/module4/ans14.png){width="8%" fig-alt="404 image"}
<div id='mcq1'></div>
<script>
    generateQuiz(
        'mcq1',
        '',
        'If  ùëò=1 , what would you predict for the above query point?',
        {
        '0': 'The point (2, 2) is the closest to (0, 0).',
        '1': 'Right, the point (2, 2) is the closest to (0, 0) and it is categorized as 1.',
        },
        '1',
    );
</script>

**Question 2**

![](../../static/module4/ans14.png){width="8%" fig-alt="404 image"}
<div id='mcq2'></div>
<script>
    generateQuiz(
        'mcq2',
        '',
        'If  ùëò=3 , what would you predict for the above query point?',
        {
        '0': '',
        '1': 'The points (2, 2), (5, 2) and (4, 3) are the closest to (0, 0). Which label is more occurring?',
        },
        '0',
    );
</script>

## ùëò-NN Classifiers True or False

<div id='mcq3'></div>
<script>
    generateQuiz(
        'mcq3',
        'Question 1',
        'The classification of the closest neighbour to the test example always contributes the most to the prediction.',
        {
        'True': 'Not always. You can select this as an option but it is not done like this by default.',
        'False': 'Great work!',
        },
        'False',
    );
</script>

<div id='mcq4'></div>
<script>
    generateQuiz(
        'mcq4',
        'Question 2',
        'The <code>n_neighbors</code> hyperparameter must be less than the number of examples in the training set.',
        {
        'True': 'Nice work.',
        'False': 'You can‚Äôt assign <code>n_neighbors</code> to a value greater than the possible number of examples in the training set.',
        },
        'True',
    );
</script>

<div id='mcq5'></div>
<script>
    generateQuiz(
        'mcq5',
        'Question 3',
        'Similar to decision trees, ùëò-NNs finds a small set of good features.',
        {
        'True': 'ùëò-NNs use all the features!',
        'False': 'Great work!',
        },
        'False',
    );
</script>


## Predicting with a ùëò-NN-Classifier

**Instructions:**    
Running a coding exercise for the first time could take a bit of time for everything to load.  Be patient, it could take a few minutes. 

**When you see `____` in a coding exercise, replace it with what you assume to be the correct code.  Run it and see if you obtain the desired output.  Submit your code to validate if you were correct.**

_**Make sure you remove the hash (`#`) symbol in the coding portions of this question.  We have commented them so that the line won't execute and you can test your code after each step.**_

Let's try to classify some Pok√©mon from the Pok√©mon dataset. How well does our model do on the training data?

```{pyodide}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# Loading in the data
pokemon_df = pd.read_csv('data/pokemon.csv')
pokemon_df
```

**Tasks:**

- Create a `KNeighborsClassifier` model with `n_neighbors` equal to 5 and name it `model`.
- Train your model on `X_train` and `y_train` (Hint: you may want to use `.to_numpy()`).
- Score your model on the training set using `.score()` and save it in an object named `train_score`.
- Score your model on the test set using `.score()` and save it in an object named `test_score`.

```{pyodide}
#| setup: true
#| exercise: predicting_with_a_knn_classifier
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from src.utils import assert_accuracy_almost

pokemon_df = pd.read_csv('data/pokemon.csv')
```


```{pyodide}
#| exercise: predicting_with_a_knn_classifier
# Split the data
train_df, test_df = train_test_split(pokemon_df, test_size=0.2, random_state=123)

# Define X and y for the training set
X_train = train_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_train = train_df['legendary']

# Define X and y for the test set 
X_test = test_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_test = test_df['legendary']

# Create a KNeighborsClassifier model with n_neighbors equal to 5 and name it model
____ =  ____

# Train your model
____

# Score your model on the training set using score and save it in an object named train_score
____ = ____

# Score your model on the test set using score and save it in an object named test_score
____ = ____

dict = {
  "train": round(train_score, 4),
  "test": round(test_score, 4)
}
dict
```

```{pyodide}
#| exercise: predicting_with_a_knn_classifier
#| check: true
train_df, test_df = train_test_split(pokemon_df, test_size=0.2, random_state=123)
X_train = train_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_train = train_df['legendary']
X_test = test_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_test = test_df['legendary']

model =  KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train.to_numpy())
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)
assert_accuracy_almost([train_score, test_score], list(result.values()))
```

:::: { .hint exercise="predicting_with_a_knn_classifier"}
::: { .callout-note collapse="false"}

## Hint 1

- Are you using ` KNeighborsClassifier(n_neighbors=5)`?
- Are you using `model.fit(X_train, y_train.to_numpy())`?
- Are you using `model.score(X_train, y_train)` to find the training score?
- Are you using `model.score(X_test, y_test)` to find the test score?

:::
::::

:::: { .solution exercise="predicting_with_a_knn_classifier" }
::: { .callout-tip collapse="false"}

## Fully worked solution:

```{pyodide}
# Split the data
train_df, test_df = train_test_split(pokemon_df, test_size=0.2, random_state=123)

# Define X and y for the training set
X_train = train_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_train = train_df['legendary']

# Define X and y for the test set 
X_test = test_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y_test = test_df['legendary']

# Create a KNeighborsClassifier model with n_neighbors equal to 5 and name it model
model =  KNeighborsClassifier(n_neighbors=5)

# Train your model
model.fit(X_train, y_train.to_numpy())

# Score your model on the training set using score and save it in an object named train_score
train_score = model.score(X_train, y_train)

# Score your model on the test set using score and save it in an object named test_score
test_score = model.score(X_test, y_test)

dict = {
  "train": round(train_score, 4),
  "test": round(test_score, 4)
}
dict
```

:::
::::