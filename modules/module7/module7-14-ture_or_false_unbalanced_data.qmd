---
format: live-html
---

<script src='../../src/quiz.js'></script>

# 4.1. Exercises

## True or False: Unbalanced Data

<div id='mcq1'></div>
<script>
    generateQuiz(
        'mcq1',
        'Question 1',
        'When using <code>StratifiedKFold</code>, our data is no longer a random sample.',
        {
        'True': 'Although this is true. Sometimes it’s not a big problem.',
        'False': 'Are you sure?',
        },
        'True',
    );
</script>

<div id='mcq2'></div>
<script>
    generateQuiz(
        'mcq2',
        'Question 2',
        'If method A gets a higher accuracy than method B, that means its precision is also higher. .',
        {
        'True': 'Precision is independent from accuracy.',
        'False': '',
        },
        'False',
    );
</script>

## Balancing our Data in Action

**Instructions:**    
Running a coding exercise for the first time could take a bit of time for everything to load.  Be patient, it could take a few minutes. 

**When you see `____` in a coding exercise, replace it with what you assume to be the correct code.  Run it and see if you obtain the desired output.  Submit your code to validate if you were correct.**

_**Make sure you remove the hash (`#`) symbol in the coding portions of this question.  We have commented them so that the line won't execute and you can test your code after each step.**_

Let's bring back the Pokémon dataset that we've seen a few times. 

After splitting and inspecting the target column we see that this dataset is fairly unbalanced. 

In this case, our positive label is whether a Pokémon is **"legendary"**  or not. In our dataset, a value of 1 represents a legendary Pokémon and 0 is a non-legendary one.  

```{pyodide}
import pandas as pd
from sklearn.model_selection import train_test_split


pk_df = pd.read_csv('data/pokemon.csv')

train_df, test_df = train_test_split(pk_df, test_size=0.2, random_state=1)

X_train_big = train_df.drop(columns=['legendary'])
y_train_big = train_df['legendary']
X_test = test_df.drop(columns=['legendary'])
y_test = test_df['legendary']

X_train, X_valid, y_train, y_valid = train_test_split(X_train_big, 
                                                      y_train_big, 
                                                      test_size=0.3, 
                                                      random_state=123)

print(y_train.value_counts())
```

Let's see how our measurements differ when we balance our datasets.

```{pyodide}
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.metrics import classification_report

numeric_features = ["deck_no",  
                    "attack",
                    "defense" ,
                    "sp_attack",
                    "sp_defense",
                    "speed",
                    "capture_rt",
                    "total_bs"]

categorical_features = ["type"]

numeric_transformer = make_pipeline(
    SimpleImputer(strategy="median"), 
    StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore"))

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features)
)

pk_df
```

**Tasks:**

- Build a pipeline containing the column transformer and an SVC model with default hyperparameters. Fit this pipeline and name it `pipe_unbalanced`.
- Predict your values on the validation set and save them in an object named `unbalanced_predicted`.
- Using sklearn tools, print a classification report comparing the validation y labels to `unbalanced_predicted`. Set `digits=3`. 

```{pyodide}
#| setup: true
#| exercise: balancing_our_data_in_action_unbalanced
import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from src.utils import assert_accuracy_almost

pk_df = pd.read_csv('data/pokemon.csv')

train_df, test_df = train_test_split(pk_df, test_size=0.2, random_state=1)

X_train_big = train_df.drop(columns=['legendary'])
y_train_big = train_df['legendary']
X_test = test_df.drop(columns=['legendary'])
y_test = test_df['legendary']

X_train, X_valid, y_train, y_valid = train_test_split(X_train_big, 
                                                      y_train_big, 
                                                      test_size=0.3, 
                                                      random_state=123)

numeric_features = ["deck_no",  
                    "attack",
                    "defense" ,
                    "sp_attack",
                    "sp_defense",
                    "speed",
                    "capture_rt",
                    "total_bs"]

categorical_features = ["type"]

numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore"))

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features))
```


```{pyodide}
#| exercise: balancing_our_data_in_action_unbalanced
# Build a pipeline containing the column transformer and an SVC model
# Name this pipeline pipe_unbalanced
____ = ____

# Fit your unbalanced pipeline on the training data
____.____

# Predict your values on the validation set
# Save them in an object named unbalanced_predicted
____ = ____

# Using sklearn tools, print a classification_report from the validation set
# Use the code below for checking purposes, and do not use print.
# To obtain a more readable version of the report, remove output_dict=true and call print.
____(____, ____, ____, output_dict=true)
```

```{pyodide}
#| exercise: balancing_our_data_in_action_unbalanced
#| check: true

assert result is not None, "Please do not use print statements for the checking purposes."
assert isinstance(result, dict), "Please output a dict for the checking purposes."

pipe_unbalanced = make_pipeline(preprocessor, SVC())
pipe_unbalanced.fit(X_train, y_train);
unbalanced_predicted = pipe_unbalanced.predict(X_valid)
solution = classification_report(y_valid, unbalanced_predicted, digits=2, output_dict=True)

assert list(solution.keys()) == list(result.keys()), "Have you called classification_report with the correct arguments?"
assert list(solution["1"].keys()) == list(result["1"].keys()), "Have you called classification_report with the correct arguments?"
assert_accuracy_almost(list(solution["1"].values()), list(result["1"].values()))
```

:::: { .hint exercise="balancing_our_data_in_action_unbalanced"}
::: { .callout-note collapse="false"}

## Hint 1

- Are you coding `unbalanced_predicted` as `make_pipeline(preprocessor, SVC())`. 
- Are you fitting on the training set?
- Are you building a classification report with `classification_report(y_valid, unbalanced_predicted, digits=2)`?

:::
::::

:::: { .solution exercise="balancing_our_data_in_action_unbalanced" }
::: { .callout-tip collapse="false"}

## Fully worked solution:

```{pyodide}
# Build a pipeline containing the column transformer and an SVC model
# Name this pipeline pipe_unbalanced
pipe_unbalanced = make_pipeline(preprocessor, SVC())

# Fit your unbalanced pipeline on the training data
pipe_unbalanced.fit(X_train, y_train);

# Predict your values on the validation set
# Save them in an object named unbalanced_predicted
unbalanced_predicted = pipe_unbalanced.predict(X_valid)

# Using sklearn tools, print a classification_report from the validation set
print(classification_report(y_valid, unbalanced_predicted, digits=2))
#classification_report(y_valid, unbalanced_predicted, digits=2, output_dict=True) # for checking purposes
```

:::
::::

<br>

**Tasks:**

- Next, build a pipeline containing the column transformer and an SVC model but this time setting `class_weight="balanced"` in the SVM classifier. Name this pipeline in an object called `pipe_balanced` and fit it on the training data. 
- Predict values on the validation set using `pipe_balanced` and save them in an object named `balanced_predicted`. 
- Print another classification report comparing the validation y labels to `balanced_predicted`. 

```{pyodide}
#| setup: true
#| exercise: balancing_our_data_in_action_balanced
import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from src.utils import assert_accuracy_almost

pk_df = pd.read_csv('data/pokemon.csv')

train_df, test_df = train_test_split(pk_df, test_size=0.2, random_state=1)

X_train_big = train_df.drop(columns=['legendary'])
y_train_big = train_df['legendary']
X_test = test_df.drop(columns=['legendary'])
y_test = test_df['legendary']

X_train, X_valid, y_train, y_valid = train_test_split(X_train_big, 
                                                      y_train_big, 
                                                      test_size=0.3, 
                                                      random_state=123)

numeric_features = ["deck_no",  
                    "attack",
                    "defense" ,
                    "sp_attack",
                    "sp_defense",
                    "speed",
                    "capture_rt",
                    "total_bs"]

categorical_features = ["type"]

numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore"))

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features))
```


```{pyodide}
#| exercise: balancing_our_data_in_action_balanced
# Build another pipeline containing the column transformer and an SVC model
# This time use the parameter class_weight="balanced"
# Name this pipeline pipe_balanced
____ = ____

# Fit your balanced pipeline on the training data
____.____

# Predict your values on the validation set
# Save them in an object named balanced_predicted
____ = ____

# Using sklearn tools, print a classification_report from the validation set
# Use the code below for checking purposes, and do not use print.
# To obtain a more readable version of the report, remove output_dict=true and call print.
____(____, ____, ____, output_dict=true)
```

```{pyodide}
#| exercise: balancing_our_data_in_action_balanced
#| check: true

assert result is not None, "Please do not use print statements for the checking purposes."
assert isinstance(result, dict), "Please output a dict for the checking purposes."

pipe_balanced = make_pipeline(preprocessor, SVC(class_weight="balanced"))
pipe_balanced.fit(X_train, y_train);
balanced_predicted = pipe_balanced.predict(X_valid)
solution = classification_report(y_valid, balanced_predicted, digits=2, output_dict=True)

assert list(solution.keys()) == list(result.keys()), "Have you called classification_report with the correct arguments?"
assert list(solution["1"].keys()) == list(result["1"].keys()), "Have you called classification_report with the correct arguments?"
assert_accuracy_almost(list(solution["1"].values()), list(result["1"].values()))
```

:::: { .hint exercise="balancing_our_data_in_action_balanced"}
::: { .callout-note collapse="false"}

## Hint 1

- Are you building `make_pipeline(preprocessor, SVC(class_weight="balanced"))` and fitting it?
- Are you predicting the values from the balanced pipeline using `pipe_balanced.predict(X_valid)` and naming it `balanced_predicted`?
- Are you building a classification report with `classification_report(y_valid, balanced_predicted, digits=2)`?

:::
::::

:::: { .solution exercise="balancing_our_data_in_action_balanced" }
::: { .callout-tip collapse="false"}

## Fully worked solution:

```{pyodide}
# Build another pipeline containing the column transformer and an SVC model
# This time use the parameter class_weight="balanced"
# Name this pipeline pipe_balanced
pipe_balanced = make_pipeline(preprocessor, SVC(class_weight="balanced"))

# Fit your balanced pipeline on the training data
pipe_balanced.fit(X_train, y_train);

# Predict your values on the validation set
# Save them in an object named balanced_predicted
balanced_predicted = pipe_balanced.predict(X_valid)

# Using sklearn tools, print a classification_report from the validation set
print(classification_report(y_valid, balanced_predicted, digits=2))
#classification_report(y_valid, balanced_predicted, digits=2, output_dict=True) # for checking purposes
```

:::
::::

<br>

<div id='mcq3'></div>
<script>
    generateQuiz(
        'mcq3',
        'Question 1',
        'What happened with precision and recall when we balanced our class weights?',
        {
        'Precision and recall both increased': 'Are you looking at the wrong label for the positive class? <code>1</code> is our positive class in this situation.',
        'Precision increased and recall decreased': 'Are you looking at the wrong label for the positive class? <code>1</code> is our positive class in this situation.',
        'Precision and recall both decreased': 'Are you looking at the wrong label for the positive class? <code>1</code> is our positive class in this situation.',
        'Precision decreased and recall increased': 'Nice work! We sacrificed some precision for a better recall measurement.',
        },
        'Precision decreased and recall increased',
    );
</script>

<div id='mcq4'></div>
<script>
    generateQuiz(
        'mcq4',
        'Question 2',
        'Did our accuracy increase or decrease when we used balanced class weights?',
        {
        'Increase': 'Not this time.',
        'Decrease': '',
        },
        'Decrease',
    );
</script>
