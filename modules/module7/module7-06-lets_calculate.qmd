---
format: live-html
---

<script src='../../src/quiz.js'></script>

# 2.1. Exercises

## Let's Calculate

![](../../static/module7/Q2.png){fig-align="center" width="60%" fig-alt="404 image"}

For the next few questions, use the confusion matrix above and assume that **Forward** is the positive label. 

<div id='mcq1'></div>
<script>
    generateQuiz(
        'mcq1',
        'Question 1',
        'Calculate the recall.',
        {
        '0.86': '',
        '0.83': 'Are you sure you are calculating recall?',
        '0.87': 'Are you sure you are using Forward are your positive label?',
        '0.90': 'Are you sure you are calculating recall?',
        },
        '0.86',
    );
</script>

<div id='mcq2'></div>
<script>
    generateQuiz(
        'mcq2',
        'Question 2',
        'Calculate the precision.',
        {
        '0.86': 'Are you sure you are calculating recall?',
        '0.83': '',
        '0.87': 'Are you sure you are calculating recall?',
        '0.90': 'Are you sure you are using Forward are your positive label?',
        },
        '0.83',
    );
</script>

<div id='mcq3'></div>
<script>
    generateQuiz(
        'mcq3',
        'Question 3',
        'What is the f1 score?',
        {
        '0.84': '',
        '0.88': 'Are you sure you are calculating f1? f1 = (2 * precision * recall) / (precision + recall)',
        '0.82': 'Are you sure you are calculating f1? f1 = (2 * precision * recall) / (precision + recall)',
        '0.90': 'Are you sure you are calculating f1? f1 = (2 * precision * recall) / (precision + recall)',
        },
        '0.84',
    );
</script>

## True or False: Measurements

<div id='mcq4'></div>
<script>
    generateQuiz(
        'mcq4',
        'Question 1',
        'In spam classification, false positives are more damaging than false negatives (assume "positive" means the email is spam, "negative" means itâ€™s not).',
        {
        'True': '',
        'False': 'What would be worse, getting a spam email, or not getting an important email that was sent to junk?',
        },
        'True',
    );
</script>

<div id='mcq5'></div>
<script>
    generateQuiz(
        'mcq5',
        'Question 2',
        'In medical diagnosis, high recall is more important than high precision.',
        {
        'True': 'Good job!',
        'False': 'We must identify as many of the positive values instead of assessing how many of our predicted positive labels are true.',
        },
        'True',
    );
</script>

## Using Sklearn to Obtain Different Measurements

**Instructions:**    
Running a coding exercise for the first time could take a bit of time for everything to load.  Be patient, it could take a few minutes. 

**When you see `____` in a coding exercise, replace it with what you assume to be the correct code.  Run it and see if you obtain the desired output.  Submit your code to validate if you were correct.**

_**Make sure you remove the hash (`#`) symbol in the coding portions of this question.  We have commented them so that the line won't execute and you can test your code after each step.**_

Let's calculate some measurements from our basketball dataset from the previous question.

```{pyodide}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

# Loading in the data
bball = pd.read_csv('data/bball_cm.csv')

train_df, test_df = train_test_split(bball, test_size=0.2, random_state=1)

X_train_big = train_df.drop(columns=['full_name', 'jersey',
                                     'b_day', 'college', 'position'])
y_train_big = train_df['position']
X_test = test_df.drop(columns=['full_name', 'jersey',
                               'b_day', 'college', 'position'])
y_test = test_df['position']

X_train, X_valid, y_train, y_valid = train_test_split(X_train_big, 
                                                      y_train_big, 
                                                      test_size=0.3, 
                                                      random_state=123)

numeric_features = [
    "rating",
    "height",
    "weight",
    "salary",
    "draft_year",
    "draft_round",
    "draft_peak"]

categorical_features = ["team", "country"]

numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore"))

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features))

bball
```

**Tasks:**

- Import the precision, recall, f1 and classification report libraries. 
- Predict the values on `X_valid` using the `pipe_unbalanced` and the `.predict()` function and save the result in an object named `predicted_y`.
- Using sklearn tools, calculate precision, recall and f1 scores and save them in the respective names `precision`, `recall`, and `f1`. Make sure you are comparing the true `y_valid` labels to the predicted labels. You will need to assign a positive label to the "Forward"(`F`) position. This can be specified in the `pos_label` of each function. Round each calculation to 3 decimal places.
- Print a classification report of all the measurements comparing `y_valid` and `predicted_y` and assigning the `target_names` argument to `["F", "G"]`. You can use the `digits` function to round all the calculations to 3 decimal places.

```{pyodide}
#| setup: true
#| exercise: using_sklearn_to_obtain_different_measurements
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from src.utils import assert_accuracy_almost

bball = pd.read_csv('data/bball_cm.csv')

train_df, test_df = train_test_split(bball, test_size=0.2, random_state=1)

X_train_big = train_df.drop(columns=['full_name', 'jersey',
                                     'b_day', 'college', 'position'])
y_train_big = train_df['position']
X_test = test_df.drop(columns=['full_name', 'jersey',
                               'b_day', 'college', 'position'])
y_test = test_df['position']

X_train, X_valid, y_train, y_valid = train_test_split(X_train_big, 
                                                      y_train_big, 
                                                      test_size=0.3, 
                                                      random_state=123)

numeric_features = [
    "rating",
    "height",
    "weight",
    "salary",
    "draft_year",
    "draft_round",
    "draft_peak"]

categorical_features = ["team", "country"]

numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder(handle_unknown="ignore"))

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features))
```


```{pyodide}
#| exercise: using_sklearn_to_obtain_different_measurements
# Build a pipeline containing the column transformer and an SVC model
pipe_bb = make_pipeline(preprocessor, SVC())

# Fit your pipeline on the training data
pipe_bb.fit(X_train, y_train);

# Predict your values on the test set
# Save them in an object named predicted_y
____ = ____

# Using sklearn tools, calculate precision
# Save it in an object named precision
____ = ____
print("precision: ", precision)

# Using sklearn tools, calculate recall
# Save it in an object named recall
____ = ____
print("recall: ", recall)

# Using sklearn tools, calculate f1
# Save it in an object named f1
____ = ____
print("f1:", f1)

# Using sklearn tools, obtain a classification_report
# Use the code below for checking purposes, and do not use print.
# To obtain a more readable version of the report, remove output_dict=true and call print.
____(____, ____, ____, output_dict=true)
```

```{pyodide}
#| exercise: using_sklearn_to_obtain_different_measurements
#| check: true

assert result is not None, "Please do not use print statements for the checking purposes."
assert isinstance(result, dict), "Please output a dict for the checking purposes."

pipe_unbalanced = make_pipeline(preprocessor, SVC())
pipe_unbalanced.fit(X_train, y_train);
predicted_y = pipe_unbalanced.predict(X_valid)
solution = classification_report(y_valid, predicted_y, digits=3, output_dict=True)

assert list(solution.keys()) == list(result.keys()), "Have you called classification_report with the correct arguments?"
assert list(solution["F"].keys()) == list(result["F"].keys()), "Have you called classification_report with the correct arguments?"
assert_accuracy_almost(list(solution["F"].values()), list(result["F"].values()))
```

:::: { .hint exercise="using_sklearn_to_obtain_different_measurements"}
::: { .callout-note collapse="false"}

## Hint 1

- Are you using the arguments `y_valid`, `predicted_y` and `pos_label="F"` for the scoring functions?
- Are you using the arguments `y_valid`, `predicted_y`  and `digits=3` for the `classification_report` function?

:::
::::

:::: { .solution exercise="using_sklearn_to_obtain_different_measurements" }
::: { .callout-tip collapse="false"}

## Fully worked solution:

```{pyodide}
# Build a pipeline containing the column transformer and an SVC model 
# Name it pipe_unbalanced and fit it on the training data
pipe_unbalanced = make_pipeline(preprocessor, SVC())
pipe_unbalanced.fit(X_train, y_train);

# Predict your values on the validation set
# Save them in an object named predicted_y
predicted_y = pipe_unbalanced.predict(X_valid)

# Using sklearn tools, calculate precision
# Save it in an object named precision
precision = precision_score(y_valid, predicted_y, pos_label="F").round(3)
print("precision: ", precision)

# Using sklearn tools, calculate recall
# Save it in an object named recall
recall = recall_score(y_valid, predicted_y, pos_label="F").round(3)
print("recall: ", recall)

# Using sklearn tools, calculate f1
# Save it in an object named f1
f1 = f1_score(y_valid, predicted_y, pos_label="F").round(3)
print("f1:", f1)

# Using sklearn tools, print a classification_report
print(classification_report(y_valid, predicted_y, digits=3))
#classification_report(y_valid, predicted_y, digits=3, output_dict=True) # for checking purposes
```

:::
::::

<br>

<div id='mcq6'></div>
<script>
    generateQuiz(
        'mcq6',
        'Question',
        'Do the numbers in your classification report match the calculations you did using sklearn measurements?',
        {
        'Sure did!': '',
        'No': 'Maybe give it another go above!',
        },
        'Sure did!',
    );
</script>