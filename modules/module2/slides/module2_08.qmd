---
format: revealjs
title: Decision trees with continuous features
title-slide-attributes:
  data-notes: |
---

```{python}
#  | echo: false
%run src/utils.py
```

```{python}
classification_df = pd.read_csv("data/quiz2-grade-toy-classification.csv")
classification_df.head(3)
```

<br>

```{python}
X = classification_df.drop(columns=["quiz2"])
X.head(3)
```

<br>

```{python}
y = classification_df["quiz2"]
y.head(3)
```



:::{.notes} 
We’ve seen how decision trees work when our data is binary but that's not always going to be the case.

In fact, even for our quiz to toy classification dataset, we had to transform it into binary data.

Here we see our labs 1 to 4 and quiz 1 are all numeric values from 0 to 100 and they're not binary. How does our model handle this?

As usual, let’s split up our classification dataset frame into the `X` object which is our features and our `Y` object which is our target column. 
:::

--- 

```{python}
from sklearn.tree import DecisionTreeClassifier
```

```{python}
# | output: false
model = DecisionTreeClassifier()
model.fit(X, y)
```


:::{.notes} 
Just like we saw in the previous sections, we have to import our decision tree classifier from the `scikit learn.tree` library.

We build our model which is a decision tree classifier and we fit our data on our `X` and `y` objects.
:::

--- 

```{python}
# | include: false
import graphviz
from src.display_tree import display_tree

# Trees with continuous features
model = DecisionTreeClassifier()
model.fit(X, y)
display_tree(X.columns, model, "../../../static/module2/module2_08a")
```

![](../../../static/module2/module2_08a.png){fig-align="center" fig-width="80%" fig-alt="404 image"}

:::{.notes} 
Now we can see what the decision tree looks like.

The last time we looked at these trees it was splitting on values of 0.5. 

This time we have multiple different split values. 

Here, if your lab3 mark was less than 83.5 the tree predicts your `quiz2` grade to be `Not A+`. 

Before when we had binary data, features could only really be split once but now you'll notice that some features come up multiple times in the tree with a different split value. 

For example, `lab4` is split on a value of 83.5 and if we go further down the branches we have another split for lab4 at 96.5. 
:::

---

```{python}
X_subset = X[["lab4", "quiz1"]]
X_subset.head()
```


:::{.notes} 
For the next example let’s consider a subset of the data with only two features. 

This is because it's easier to visualize the splitting in 2 dimensions. 

Let’s subset the data to only include `lab4` and `quiz1`.
:::

---

## Decision boundaries

```{python}
# | output: false
depth = 1
model = DecisionTreeClassifier(max_depth=depth)
model.fit(X_subset, y)
```

```{python}
# | include: false
# Also called a decision stump
display_tree(X_subset.columns, model, "../../../static/module2/module2_08b")
```

![](../../../static/module2/module2_08b.png){fig-align="center" fig-width="80%" fig-alt="404 image"}
    
:::{.notes} 
What do we do with learned models? 

We build our model but here you may notice that we are setting an argument called `max_depth`. 

We will cover this in more detail in the next section but for now, just know that setting this constricts our model. 

Setting this to 1 constricts the model to a depth of 1 which is a decision stump.

Another way to think about them is to ask: what sort of test examples will the model classify as positive, and what sort will it classify as negative? 
    
Here we can look at this ***decision stump*** which will show us where the first feature (`lab4`) makes a divide between an `A+` and `Not A+`. 
:::

---

![](../../../static/module2/module2_08b.png){fig-align="center" width="20%" fig-alt="404 image"}

```{python}
# | echo: false
# | fig-align: center
import matplotlib.pyplot as plt
from src.model_plotting_mg import plot_classifier

y_encoded = np.where(y == 'A+', 1, 0)
model.fit(X_subset, y_encoded)

plt.figure(figsize=(4, 4))
plot_classifier(X_subset.to_numpy(), y_encoded, model, ticks=True, lims=(70,101,70,101))
plt.xticks(fontsize= 20)
plt.yticks(fontsize= 20)
plt.xlabel('lab4', fontsize=20)
plt.ylabel('quiz1', fontsize=20)
plt.title("Decision tree with depth = %d" % (depth), fontsize=24)

plt.show()
```


:::{.notes} 
We can assume a geometric view of the data. (More on this soon)

Here the red region corresponds to the `not A+` class and the blue region corresponds to the `A+` class. 

There is a line separating the red region and the blue region which is called the **decision boundary** of the model.

In our current model, this decision boundary is created by asking one question. 
:::

---

## Another example of decision boundaries

```{python}
df = pd.read_csv('data/canada_usa_cities.csv')
df.head()
```



:::{.notes} 
Here is another example of a decision boundary which can help explain the concept more visually. 

We have the latitude and longitude locations of different cities. 

We want to predict if they are Canadian or American cities using these features.
:::

---

```{python}
chart1 = alt.Chart(df).mark_circle(size=20, opacity=0.6).encode(
    alt.X('longitude:Q', scale=alt.Scale(domain=[-140, -40]), axis=alt.Axis(grid=False)),
    alt.Y('latitude:Q', scale=alt.Scale(domain=[20, 60]), axis=alt.Axis(grid=False)),
    alt.Color('country:N', scale=alt.Scale(domain=['Canada', 'USA'],
                                           range=['red', 'blue']))
)
chart1
```

```{python}
# | include: false
chart1.save('../../../static/module2/chart1.png')
```



:::{.notes} 
Now we're plotting our latitude and longitude and you can see all of the red dots are Canadian cities and all the blue dots are American cities. 
:::

---

## Real boundary between Canada and USA

![](../../../static/module2/canada-us-border.jpg){fig-align="center" width="70%"}

**Attribution:**  <a href="https://sovereignlimits.com/blog/u-s-canada-border-history-disputes" target="_blank">sovereignlimits.com</a> 

:::{.notes} 
We can compare this with the actual border between Canada and the U. S. 
:::

# Let’s apply what we learned!
