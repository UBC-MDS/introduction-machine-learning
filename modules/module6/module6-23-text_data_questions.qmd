---
format: live-html
---

<script src='../../src/quiz.js'></script>

# 6.1. Exercises

## Text Data Questions

```
X = [ "Take me to the river",
    "Drop me in the water",
    "Push me in the river",
    " dip me in the water"]

```

<div id='mcq1'></div>
<script>
    generateQuiz(
        'mcq1',
        'Question 1',
        'What is the size of the vocabulary for the examples above?',
        {
        '20': 'This is the total number of words.',
        '5': 'This is for the first observation only.',
        '10': 'Got it!',
        '11': 'Are you counting a word twice?',
        },
        '10',
    );
</script>

<div id='mcq2'></div>
<script>
    generateQuiz(
        'mcq2',
        'Question 2',
        'Which of the following is not a hyperparameter of <code>CountVectorizer()</code>?',
        {
        '<code>binary</code>': 'This is a hyperparameter of <code>CountVectorizer()</code>.',
        '<code>max_features</code>': 'This is a hyperparameter of <code>CountVectorizer()</code>.',
        '<code>vocab</code>': 'This is not a hyperparameter!',
        '<code>ngram_range</code>': 'This is a hyperparameter of <code>CountVectorizer()</code>.',
        },
        '<code>vocab</code>',
    );
</script>

## Text Data True or False

<div id='mcq3'></div>
<script>
    generateQuiz(
        'mcq3',
        'Question 1',
        'As you increase the value for the <code>max_features</code> hyperparameter of <code>CountVectorizer</code>, the training score is likely to go up.',
        {
        'True': 'Great! The model is becoming more complex.',
        'False': 'Increasing the value of <code>max_features</code> means we include each and every word from the training data in the dictionary and the training score is likely to go up.',
        },
        'True',
    );
</script>

<div id='mcq4'></div>
<script>
    generateQuiz(
        'mcq4',
        'Question 2',
        'If we encounter a word in the validation or the test split that’s not available in the training data, we’ll get an error.',
        {
        'True': 'If the word isn’t in the dictionary, we would just ignore the word.',
        'False': '',
        },
        'False',
    );
</script>


## CountVectorizer with Disaster Tweets

**Instructions:**    
Running a coding exercise for the first time could take a bit of time for everything to load.  Be patient, it could take a few minutes. 

**When you see `____` in a coding exercise, replace it with what you assume to be the correct code.  Run it and see if you obtain the desired output.  Submit your code to validate if you were correct.**

_**Make sure you remove the hash (`#`) symbol in the coding portions of this question.  We have commented them so that the line won't execute and you can test your code after each step.**_

We are going to bring in a new dataset for you to practice on. 

This dataset contains a text column containing tweets associated with disaster keywords and a target column denoting whether a tweet is about a real disaster (1) or not (0). (<a href="https://www.kaggle.com/vstepanenko/disaster-tweets" target="_blank"><b>Source</b></a>)

In this question, we are going to explore how changing the value of `max_features` affects our training and cross-validation scores.

```{pyodide}
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.feature_extraction.text import CountVectorizer

# Loading in the data
tweets_df = pd.read_csv('data/balanced_tweets.csv').dropna(subset=['target'])
tweets_df
```

**Tasks:**

- Split the dataset into the feature table `X` and the target value `y`. `X` will be the single column `text` from the dataset wheras `target` will be your `y`. 
- Split your data into your training and testing data using a text size of 20% and a random state of 7. 
- Make a pipeline with `CountVectorizer` as the first step and `SVC()` as the second. Name the pipeline `pipe`. 
- Perform RandomizedSearchCV using the parameters specified in `param_grid` and name the search `tweet_search`.
- Don't forget to fit your grid search.
- What is the best `max_features` value? Save it in an object name `tweet_feats`.
- What is the best score? Save it in an object named `tweet_val_score`.
- Score the optimal model on the test set and save it in an object named `tweet_test_score`.

NOTE: This may take a few minutes to produce an output. Please be patient.

```{pyodide}
#| setup: true
#| exercise: countvectorizer_with_disaster_tweets
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.svm import SVC
from sklearn.feature_extraction.text import CountVectorizer
from src.utils import print_correct_msg

tweets_df = pd.read_csv('data/balanced_tweets.csv').dropna(subset=['target'])
```


```{pyodide}
#| exercise: countvectorizer_with_disaster_tweets
# Split the dataset into the feature table `X` and the target value `y`
____ = ____
____ = ____

# Split the dataset into X_train, X_test, y_train, y_test 
____ = ____


param_grid = {
    "countvectorizer__max_features": range(1,1000)
}

# Make a pipeline with CountVectorizer as the first step and SVC as the second 
____ = ____

# perform RandomizedSearchCV using the parameters specified in param_grid
# Don't forget to fit this on the training data
____ = ____(____, ____, n_jobs=-1, cv=5,
            return_train_score=True, n_iter=10,
            Random_state=2020)
____.____(____)

# What is the best max_features value? Save it in an object name tweet_feats
____ = ____

# What is the best score? Save it in an object named tweet_val_score
____ = ____

# Score the optimal model on the test set and save it in an object named tweet_test_score
____ = ____

dict = {
    "tweet_feats": tweet_feats,
    "tweet_val_score": tweet_val_score,
    "tweet_test_score": tweet_test_score
}
dict
```

```{pyodide}
#| exercise: countvectorizer_with_disaster_tweets
#| check: true
assert result["tweet_feats"] > 880, "The best value for max features is incorrect. Are you fitting the model properly?"
assert round(result["tweet_val_score"],3) > 0.810, "The value for tweet_val_score is incorrect. Are you fitting the model properly?"
assert round(result["tweet_test_score"],3) > 0.810, "The value for tweet_test_score is incorrect. Are you scoring on the test data?"
print_correct_msg()
```

:::: { .hint exercise="countvectorizer_with_disaster_tweets"}
::: { .callout-note collapse="false"}

## Hint 1

- Are you splitting using `train_test_split()`
- Are you using `make_pipeline(CountVectorizer(), SVC())`?
- Are you using `RandomizedSearchCV()` and calling `pipe` and `param_grid` as the first 2 arguments?
- Are you naming the randomized grid search `tweet_search`?
- Are you fitting `tweet_search`?
- Are you using `tweet_search.best_params_['countvectorizer__max_features']` to get the optimal number of features?
- Are you using `tweet_search.best_score_` to get the best validation score?
- Are you using `tweet_search.score(X_test, y_test)` to get the test score?

:::
::::

:::: { .solution exercise="countvectorizer_with_disaster_tweets" }
::: { .callout-tip collapse="false"}

## Fully worked solution:

```{pyodide}
# Split the dataset into the feature table `X` and the target value `y`
X = tweets_df['text']
y = tweets_df['target']

# Split the dataset into X_train, X_test, y_train, y_test 
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7)


param_grid = {
    "countvectorizer__max_features": range(1,1000)
}

# Make a pipeline with CountVectorizer as the first step and SVC as the second 
pipe = make_pipeline(CountVectorizer(), SVC())

# perform RandomizedSearchCV using the parameters specified in param_grid
# Don't forget to fit this on the training data
tweet_search = RandomizedSearchCV(pipe, param_grid, n_jobs=-1, cv=5,
                                  return_train_score=True, n_iter=10,
                                   random_state=2020)
tweet_search.fit(X_train, y_train)

# What is the best max_features value? Save it in an object name tweet_feats
tweet_feats = tweet_search.best_params_['countvectorizer__max_features']

# What is the best score? Save it in an object named tweet_val_score
tweet_val_score = tweet_search.best_score_

# Score the optimal model on the test set and save it in an object named tweet_test_score
tweet_test_score = tweet_search.score(X_test, y_test)

dict = {
    "tweet_feats": tweet_feats,
    "tweet_val_score": tweet_val_score,
    "tweet_test_score": tweet_test_score
}
dict
```

:::
::::