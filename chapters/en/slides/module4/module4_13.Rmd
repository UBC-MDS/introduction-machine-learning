---
params:
  dynamictitle: "module4_14"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module4/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz
from sklearn.model_selection import cross_validate

from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module4/"
```


type: slides

# ùëò -Nearest Neighbours (ùëò-NNs) Classifier

Notes: <br>

---


<br>
<br>
<center><img src="/module4/scatter.png"  width = "50%" alt="404 image" /></center>


Notes: 

Now we know how to measure distance and find examples that are closest to a point but how can that be translated into a predictive model? 

Here is a toy data for binary classification.

We want to predict the point in grey.

An intuitive way to do this is to predict the grey point using the same label as the next "closest" point (ùëò = 1)
We would predict a target of 1 (orange) in this case.


---

<br>
<br>
<center><img src="/module4/scatter_k1.png"  width = "50%" alt="404 image" /></center>


Notes: 

We would predict a target of 1 (orange) in this case.

---

<br>
<br>
<center><img src="/module4/scatter_k3.png"  width = "50%" alt="404 image" /></center>

Notes: 

We could also use the 3 closest points (ùëò = 3) and let them **vote** on the correct class.

We would predict a target of 0 (blue) in this case.

---

```{python include=FALSE}
cities_df = pd.read_csv("data/canada_usa_cities.csv")
train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)
train_df.head()
```

```{python}
small_train_df = cities_df.sample(30, random_state=90)
X_train = small_train_df.drop(columns=["country"])
y_train = small_train_df["country"]
one_city = small_train_df.sample(1, random_state=44)
one_city
```

<center><img src="/module4/point.png"  width = "63%" alt="404 image" /></center>

Notes: 

Let's return to a smaller version of our cities data now.

Here we have a single point we are calling `one_city`.

It's the green triangle we see in the plot. 

----

<center><img src="/module4/point.png"  width = "60%" alt="404 image" /></center>



```{python}
from sklearn.neighbors import KNeighborsClassifier

neigh = KNeighborsClassifier(n_neighbors=1)
neigh.fit(X_train, y_train);
neigh.predict(one_city.drop(columns=["country"]))

```


Notes: 

If we predict the closest point where ùëò = 1, we would predict a target of **Canada** (red) in this case.

---


<center><img src="/module4/point.png"  width = "60%" alt="404 image" /></center>


```{python}
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(X_train, y_train);
neigh.predict(one_city.drop(columns=["country"]))

```


Notes: 

What about with the nearest 3 cities(ùëò = 3)? 

This is still predicting Canada since the majority of the 3 nearest points to the green triangle are "Canadian". 

---

<center><img src="/module4/point.png"  width = "60%" alt="404 image" /></center>


```{python}
neigh = KNeighborsClassifier(n_neighbors=9)
neigh.fit(X_train, y_train);
neigh.predict(one_city.drop(columns=["country"]))

```


Notes: 

What about with the nearest 9 cities(ùëò = 9)? 

This is now predicting USA since the majority of the 9 nearest points are  "USA" cities. 

---

```{python include=FALSE}
cities_df = pd.read_csv("data/canada_usa_cities.csv")
X = cities_df.drop(columns=["country"])
y = cities_df["country"]
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)
```

```{python}
model = KNeighborsClassifier(n_neighbors=1)
model.fit(X_train, y_train);
```


```{python}
model.score(X_train,y_train)
```
```{python}
model.score(X_test,y_test)
```


Note: 

We can see how our model will predict both our training data and our test set using the same `fit` and `score` that we saw with dummy classifiers and decision trees.

Extra: The <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html" target="_blank">`.to_numpy()` </a> tool can help get pandas dataframes into a 2 dimensional array which is what `.score()` and `.fit()` need as inputs.


---

# Let‚Äôs apply what we learned!

Notes: <br>