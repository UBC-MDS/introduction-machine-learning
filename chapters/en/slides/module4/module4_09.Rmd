---
params:
  dynamictitle: "module4_09"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module4/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz
from sklearn.metrics.pairwise import euclidean_distances
from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module4/"
```


type: slides

# Finding the nearest neighbour

Notes: <br>

---


```{python}
cities_df = pd.read_csv("data/canada_usa_cities.csv")
train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)
train_df.head(3)
```

```{python}
dists = euclidean_distances(train_df[["latitude", "longitude"]])
dists
```

```{python}
dists.shape
```

Notes: 

Now that we know how to calculate the Euclidean distance between examples, let see how close all the cities are to all other cities in the dataset. 


---


```{python}
pd.DataFrame(dists).loc[:5,:5]
```

```{python}
np.fill_diagonal(dists, np.inf)
pd.DataFrame(dists).loc[:5,:5]
```


Notes: 

It's important that we use the `fill_diagonal()` tool to replace all the diagonal entries which is the distance from a city to itself. 

It makes sense that there those entries have a distance of 0 but if we are trying to find the city with the minimum distance, we would never be getting the closest neighbour and instead be getting itself each time. 

This is why we "fill diagonal" entries with a very large number, infinity in fact. 



---

Feature vector for city 0:
```{python}
train_df.iloc[0]
```

Distances from city 0 to 5 other cities:
```{python}
dists[0][:5]
```


Notes: Next, let's look at the distances between City 0 and the first 5 cities in the dataframe. 

---

```{python}
train_df.iloc[[0]]
```

```{python}
np.argmin(dists[0])
```

```{python}
train_df.iloc[[157]]
```


```{python}
dists[0][157]
```


Notes: 

We can find the closest city to city 0 with  <a href="https://numpy.org/doc/stable/reference/generated/numpy.argmin.html" target="_blank">`np.argmin`</a>.

The closest city from city 0 is city 157 in the training dataframe.  

It's feature vector tells us that it's city 96 (of the whole dataset)  and is located at longitude -76.3019 and latitude 44.211 in country Canada. 

That's 0.18 units away from city 0. 

---

### Finding the distances to a query point

```{python}
query_point = [[-80, 25]]
```


```{python}
dists = euclidean_distances(train_df[["longitude", "latitude"]], query_point)
dists[0:5]
```

We can find the city closest to the query point (-80, 25) using:

```{python}
np.argmin(dists)
```

The distance between the query point and closest city is:
```{python}
dists[np.argmin(dists)].item()
```


Notes: 

We can also find the distances to a new "test" or "query" city. 

This time we add a second argument in `euclidean_distances()` which has the coordinates of our query point. 

This produces an array with the distances from each city to the query point we specified. 

---



```{python}
from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(n_neighbors=1)
nn.fit(train_df[['longitude', 'latitude']]);
nn.kneighbors([[-80, 25]])
```

Notes: 

You can do the same thing using sklearn's NearestNeighbors function and we get the same thing! 

All this matches our intuition of "distance" in the real world.

And we could also extend it to points in 3D space.

In fact, we can extend it to arrays ("vectors") of any length.


---



```{python}
pokemon_df = pd.read_csv("data/pokemon.csv")
X = pokemon_df.drop(columns = ['deck_no', 'name','total_bs', 'type', 'legendary'])
y = pokemon_df[['legendary']]
X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size=0.2, random_state=123)

X_train.head()
```

Note:

Let's look at our pokemon data which will have 7 dimensions.

---

```{python}
dists = euclidean_distances(X_train[:3])
dists
```

```{python}
dists[0,2]
```

```{python}
nn = NearestNeighbors(n_neighbors=1)
nn.fit(X_train);
nn.kneighbors(X_test.iloc[[1]])
```

```{python}
X_test.to_numpy().shape
```
Notes:

The distance between pokemon 0 and pokemon 2  can be found with `dists[0,2]`. 
 
We can find the most similar Pokemon from our training data to the Pokemon 1 from the test set using `NearestNeighbors` from the Sklearn package. 
 
---

```python
nn = NearestNeighbors(n_neighbors=5)
nn.fit(X_train);
nn.kneighbors(X_test.iloc[1])
```
```out
ValueError: Expected 2D array, got 1D array instead:
array=[605  55  55  85  55  30 255 335   5].
Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.
```

```{python}
X_test.iloc[1].shape
```
```{python}
X_test.iloc[[1]].shape
```

```{python}
nn = NearestNeighbors(n_neighbors=5)
nn.fit(X_train);
nn.kneighbors(X_test.iloc[[1]])
```



Notes: 

We can also find the 5 most similar Pokemon in the training data to test Pokemon 1. 

We need to be careful though. 

A numpy array with shape (9,) is 1 dimensional where as (1, 9) is 2 dimensional which is what `kneighbors()` needs as an input. 

Now we can see the top 5 most similar pokemon.

---

# Letâ€™s apply what we learned!

Notes: <br>