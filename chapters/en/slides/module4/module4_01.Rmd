---
params:
  dynamictitle: "module4_01"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module4/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz

from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module4/"
```


type: slides

# Terminology with analogy-based models

Notes: <br>

---

## Analogy-based models

<br>
<br>

<img src='/module4/knn-motivation.png' width="100%">
<a href="https://vipl.ict.ac.cn/en/database.php" target="_blank">Attribution</a>



Notes: 

Suppose you are given the following training examples with corresponding labels and are asked to label a given test example.

An intuitive way to classify the test example is by finding the most "similar" example(s) from the training set and using that label for the test example.  

---

## Analogy-based algorithms in practice

- <a href="https://www.hertasecurity.com/en" target="_blank">Herta's High-tech Facial Recognition</a>

<center><img src="/module4/face_rec.png"  width = "20%" alt="404 image" /></center>

- Recommendation systems 

<center><img src="/module4/book_rec.png"  width = "90%" alt="404 image" /></center>


Notes: 

Examples of Analogy-based algorithms include:

- <a href="https://www.hertasecurity.com/en" target="_blank">Herta's High-tech Facial Recognition</a>
  - Feature vectors for human faces 
  - ùëò-NN to identify which face is on their watch list
  
- Recommendation systems 

---

### Geometric view of tabular data and dimensions 


<center><img src="/module4/3d-table.png"  width = "100%" alt="404 image" /></center>

Notes: 

To understand analogy-based algorithms it's useful to think of data as points in a high dimensional space. 

- Our `X` represents  the problem in terms of relevant **features**  with one dimension for each **feature** (column).

- Examples are **points in a number-of-features-dimensional space**. 


---

```{python}
cities_df = pd.read_csv("data/canada_usa_cities.csv")
train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)
train_df.head()
```


Notes: 

Let's look at our Canadian and United States cities. 

How many dimensions (features) are there in this cities data? 

If you said 2, then you are off to a good start. 

---

```{python}
cities_plot = alt.Chart(train_df).mark_circle(size=20, opacity=0.6).encode(
    alt.X('longitude:Q', scale=alt.Scale(domain=[-140, -40])),
    alt.Y('latitude:Q', scale=alt.Scale(domain=[20, 60])),
    alt.Color('country:N', scale=alt.Scale(domain=['Canada', 'USA'],
                                           range=['red', 'blue']))
)
cities_plot
```

```{python include =FALSE}
cities_plot.save(path + 'cities_plot.png')
```

<img src="/module4/cities_plot.png" alt="A caption" width="50%" />


Notes: 

We can visualize these 2 dimensions in a 2D graph. 

---

### Dimensions

```{python}
grades_df = pd.read_csv("data/quiz2-grade-toy-classification.csv")
grades_df.head()
```


```{python}
X = grades_df.drop(columns=['quiz2'])
X.shape[1]
```


Notes: 

Recall the quiz dataset that we've seem a few times?

How many dimensions (features) would this dataset have? 

The number of features in the grades dataset can be checked using `.shape`. 


---

### Dimensions in ML problems 

Dimensions:

- Dimensions‚âà20 : Low dimensional
- Dimensions‚âà1000: Medium dimensional
- Dimensions‚âà100,000:  High dimensional

Notes: 


In ML, usually we deal with high dimensional problems where examples are hard to visualize.

- Dimensions‚âà20  is considered low dimensional
- Dimensions‚âà1000  is considered medium dimensional
- Dimensions‚âà100,000  is considered high dimensional


---

### Feature vectors 

**Feature vector**: a vector composed of feature values associated with an example.

```{python}
train_df.head()
```


An example feature vector from the cities dataset:
```{python}
train_df.drop(columns=["country"]).iloc[0].round(2).to_numpy()
```

An example feature vector from the grading dataset:

```{python}
grades_df.drop(columns=['quiz2']).iloc[0].round(2).to_numpy()
```

Notes: 

<br>

---


# Let‚Äôs apply what we learned!

Notes: <br>