---
params:
  dynamictitle: "module1_17"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module1/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from image_classifier import classify_image

from IPython.display import HTML, display
from PIL import Image, ImageFile
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

```


type: slides

# Dummy Regression

Notes: <br>

---

### Building a baseline regression model

<br>
<br>
<br>
Baseline model:
 **Averge target value**: always predicts the mean of the training set.



Notes: 

Let's build a ***baseline*** simple machine learning algorithm based on simple rules of thumb. 

For a regression problem, we are going to build a baseline model that always predicts the mean target value in the training set. 


---


## Data 

```{python}
classification_df = pd.read_csv("data/quiz2-grade-toy-regression.csv")
classification_df.head()
```



Notes: 

Let's bring in our regression problem data now. 

For this example, we are going to be working with the quiz2 regression data that we have seen previously. 

---

## 1. Create  ùëã  and  ùë¶

ùëã  ‚Üí Feature vectors <br>
ùë¶  ‚Üí Target

```{python}
X = classification_df.drop(columns=["quiz2"])
y = classification_df["quiz2"]
```


Notes: 

Just like before, we separate our data into the feature table and the target, also known as ùëã and ùë¶. 



<br>

---

## 2. Create a regressor object

- `import` the appropriate regressor, in this case, `DummyRegressor`.
- Create an object of the regressor. 

```{python}
from sklearn.dummy import DummyRegressor

dummy_reg = DummyRegressor(strategy="mean")
```


Notes: 

This time instead of importing `DummyClassifier()`, we import `DummyRegessor` which will be used to create our baseline regression model. 

We specify in the `strategy` argument `mean`. With this strategy, the model will predict the mean target value in the training data. 

Here we are naming our model `dummy_reg`.



---

## 3. Fit the regressor

```{python results = 'hide'}
dummy_reg.fit(X, y)
```


Notes: 

Once we have created and named our regressor, we give it data to train on. 


---

## 4. Predict the target of given examples

We can predict the mean of examples by calling `predict` on the classifier object. 

```{python}
single_obs = X.loc[[2]]
single_obs
```

```{python}
dummy_reg.predict(single_obs)
```






Notes: 


Since our model has been trained on existing data, we can predict the targets.

For observation 2, the model predicts a value of `86.29`

---

```{python}
X
```



```{python}
dummy_reg.predict(X)
```





Notes:

In fact, the model predicts the same value for all the observations.

---

## 5. Scoring your model

In the regression setting, `.score()` gives the R^2 of the model, i.e. the coefficient of determination of the prediction.




```{python}
print("The accuracy of the model on the training data:", (dummy_reg.score(X, y)).round(3))
```

Notes: 

The best possible score for any model is 1.0 and it can be a negative (because the model can be arbitrarily worse). 

We will talk about this value further in the course, but for now, all you need to know is that for dummy regressors, the output of `.score()` when using a dummy regressor with a `strategy` argument value of `mean`, will be 0.0.


---

# Let‚Äôs apply what we learned!

Notes: <br>